# Architecture: FEAT-003 - Specialist Agent with Vector Search

**Feature ID:** FEAT-003
**Status:** Proposed
**Decision Date:** 2025-10-26

---

## Context

EVI 360 needs a Dutch-language RAG system for workplace safety specialists to query 10,833 ingested guideline chunks. The system must prove retrieval accuracy and response quality without over-engineering (no tiers, products, or advanced memory for MVP).

**Technical Challenge:**
- Existing codebase has 90% of needed infrastructure (API, tools, database)
- Need to wire specialist agent to existing search tools
- Must support Dutch language end-to-end (query â†’ search â†’ response)
- CLI expects API server, not direct agent access

**Scope of Decision:**
How to architect the MVP query flow from CLI to database and back.

---

## System Architecture

### High-Level Component Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER LAYER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  CLI (cli.py)                                             â”‚   â”‚
â”‚  â”‚  - Colored terminal output                                â”‚   â”‚
â”‚  â”‚  - aiohttp HTTP client                                    â”‚   â”‚
â”‚  â”‚  - Streaming response handler                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ HTTP POST /chat/stream
                    â”‚ {"message": "Dutch query", "session_id": "..."}
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         API LAYER                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FastAPI Server (agent/api.py)                            â”‚   â”‚
â”‚  â”‚  - Port: 8058 (APP_PORT in .env)                          â”‚   â”‚
â”‚  â”‚  - Lifecycle: DB + Neo4j initialization                   â”‚   â”‚
â”‚  â”‚  - Endpoints: /health, /chat/stream, /search              â”‚   â”‚
â”‚  â”‚  - CORS: Configured for future OpenWebUI                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ Call specialist_agent.run_stream()
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AGENT LAYER                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Specialist Agent (agent/specialist_agent.py)             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚  Pydantic AI Agent                                   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  - Model: GPT-4 (from .env LLM_API_KEY)              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  - System Prompt: SPECIALIST_SYSTEM_PROMPT (Dutch)   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  - Result Type: SpecialistResponse                   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚    {content: str, citations: List, metadata: Dict}   â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚  @tool: search_guidelines(query, limit=10)           â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  - Wraps hybrid_search_tool                          â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  - Returns: List[Dict] with chunks                   â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ Call hybrid_search_tool()
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TOOLS LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Search Tools (agent/tools.py)                            â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â”‚  hybrid_search_tool(HybridSearchInput)                    â”‚   â”‚
â”‚  â”‚  â”œâ”€ Generate embedding via OpenAI                         â”‚   â”‚
â”‚  â”‚  â”œâ”€ Call db_utils.hybrid_search()                         â”‚   â”‚
â”‚  â”‚  â””â”€ Return ChunkResult[]                                  â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â”‚  vector_search_tool(VectorSearchInput)                    â”‚   â”‚
â”‚  â”‚  â””â”€ Pure vector similarity (backup option)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ SQL function calls
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATABASE LAYER                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Database Utils (agent/db_utils.py)                       â”‚   â”‚
â”‚  â”‚  - DatabasePool (asyncpg connection pool)                 â”‚   â”‚
â”‚  â”‚  - hybrid_search(embedding, query_text, limit, weight)    â”‚   â”‚
â”‚  â”‚  - vector_search(embedding, limit)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ SELECT * FROM hybrid_search($1, $2, $3, $4)
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   POSTGRESQL DATABASE                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Tables:                                                   â”‚   â”‚
â”‚  â”‚  - documents (87 rows)                                     â”‚   â”‚
â”‚  â”‚  - chunks (10,833 rows with embeddings)                   â”‚   â”‚
â”‚  â”‚    * tier column exists but NULL (unused for MVP)         â”‚   â”‚
â”‚  â”‚    * embedding vector(1536) indexed with ivfflat          â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â”‚  Functions:                                                â”‚   â”‚
â”‚  â”‚  - hybrid_search(embedding, text, limit, weight)           â”‚   â”‚
â”‚  â”‚    * Combines vector similarity (<=> operator)            â”‚   â”‚
â”‚  â”‚    * With Dutch full-text (to_tsvector('dutch', ...))     â”‚   â”‚
â”‚  â”‚    * Returns top N chunks ranked by combined score        â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â”‚  - match_chunks(embedding, limit)                          â”‚   â”‚
â”‚  â”‚    * Pure vector similarity search                        â”‚   â”‚
â”‚  â”‚    * Fallback option (not used by default)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow: Query to Response

### Step-by-Step Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User Input (CLI)                                             â”‚
â”‚    User types: "Wat zijn de vereisten voor werken op hoogte?"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CLI â†’ API (HTTP POST)                                        â”‚
â”‚    POST http://localhost:8058/chat/stream                       â”‚
â”‚    Body: {                                                      â”‚
â”‚      "message": "Wat zijn de vereisten...",                     â”‚
â”‚      "session_id": null,  # Stateless for MVP                  â”‚
â”‚      "user_id": "cli_user",                                     â”‚
â”‚      "search_type": "hybrid"                                    â”‚
â”‚    }                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. API Endpoint Handler                                         â”‚
â”‚    async def stream_chat(request: ChatRequest):                 â”‚
â”‚      # Initialize specialist agent dependencies                 â”‚
â”‚      deps = SpecialistDeps(                                     â”‚
â”‚        session_id=generate_session_id(),                        â”‚
â”‚        user_id=request.user_id                                  â”‚
â”‚      )                                                          â”‚
â”‚                                                                 â”‚
â”‚      # Run agent with streaming                                â”‚
â”‚      async with specialist_agent.run_stream(                    â”‚
â”‚        request.message, deps=deps                               â”‚
â”‚      ) as result:                                               â”‚
â”‚        async for chunk in result.stream():                      â”‚
â”‚          yield chunk  # SSE stream                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Specialist Agent Reasoning                                   â”‚
â”‚    Agent reads system prompt (Dutch guidelines specialist)      â”‚
â”‚    Agent decides: "I need to search for 'werken op hoogte'"    â”‚
â”‚    Agent calls tool: search_guidelines()                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Tool Execution: search_guidelines()                          â”‚
â”‚    @specialist_agent.tool                                       â”‚
â”‚    async def search_guidelines(ctx, query, limit=10):           â”‚
â”‚      results = await hybrid_search_tool(                        â”‚
â”‚        HybridSearchInput(                                       â”‚
â”‚          query="werken op hoogte",                              â”‚
â”‚          limit=10,                                              â”‚
â”‚          text_weight=0.3  # 70% vector, 30% text               â”‚
â”‚        )                                                        â”‚
â”‚      )                                                          â”‚
â”‚      return format_results(results)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Hybrid Search Tool: Generate Embedding                       â”‚
â”‚    embedding = await openai.embeddings.create(                  â”‚
â”‚      model="text-embedding-3-small",                            â”‚
â”‚      input="werken op hoogte"                                   â”‚
â”‚    )                                                            â”‚
â”‚    # Returns: [0.123, -0.456, 0.789, ...] (1536 dims)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Database Utils: hybrid_search()                              â”‚
â”‚    async def hybrid_search(embedding, query_text, limit):       â”‚
â”‚      embedding_str = '[' + ','.join(map(str, embedding)) + ']' â”‚
â”‚      results = await conn.fetch(                                â”‚
â”‚        "SELECT * FROM hybrid_search($1::vector, $2, $3, $4)",   â”‚
â”‚        embedding_str,                                           â”‚
â”‚        "werken op hoogte",  # For Dutch full-text              â”‚
â”‚        10,  # limit                                             â”‚
â”‚        0.3  # text_weight                                       â”‚
â”‚      )                                                          â”‚
â”‚      return format_chunks(results)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. PostgreSQL: hybrid_search() Function                         â”‚
â”‚    WITH vector_results AS (                                     â”‚
â”‚      SELECT *, 1 - (embedding <=> $1) AS vector_sim            â”‚
â”‚      FROM chunks WHERE embedding IS NOT NULL                    â”‚
â”‚    ),                                                           â”‚
â”‚    text_results AS (                                            â”‚
â”‚      SELECT *, ts_rank_cd(                                      â”‚
â”‚        to_tsvector('dutch', content),                           â”‚
â”‚        plainto_tsquery('dutch', $2)                             â”‚
â”‚      ) AS text_sim                                              â”‚
â”‚      FROM chunks                                                â”‚
â”‚      WHERE to_tsvector('dutch', content) @@                     â”‚
â”‚            plainto_tsquery('dutch', $2)                         â”‚
â”‚    )                                                            â”‚
â”‚    SELECT *, (vector_sim * 0.7 + text_sim * 0.3) AS score      â”‚
â”‚    FROM vector_results FULL OUTER JOIN text_results             â”‚
â”‚    ORDER BY score DESC LIMIT $3                                 â”‚
â”‚                                                                 â”‚
â”‚    Returns: Top 10 chunks with content, metadata, scores        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. Tool Returns Results to Agent                                â”‚
â”‚    [                                                            â”‚
â”‚      {                                                          â”‚
â”‚        "content": "Bij werken op hoogte boven 2,5 meter...",   â”‚
â”‚        "score": 0.87,                                           â”‚
â”‚        "document_title": "NVAB Richtlijn: Werken op Hoogte",   â”‚
â”‚        "document_source": "NVAB",                               â”‚
â”‚        "chunk_id": "uuid-123"                                   â”‚
â”‚      },                                                         â”‚
â”‚      { ... 9 more chunks ... }                                  â”‚
â”‚    ]                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. Agent Synthesis (GPT-4)                                     â”‚
â”‚     Agent receives search results + original query              â”‚
â”‚     Agent follows Dutch system prompt:                          â”‚
â”‚       1. Summarize answer (2-3 sentences)                       â”‚
â”‚       2. Cite â‰¥2 guidelines with quotes                         â”‚
â”‚       3. Provide practical advice                               â”‚
â”‚                                                                 â”‚
â”‚     Agent generates SpecialistResponse:                         â”‚
â”‚       content: "Voor werken op hoogte gelden..."  (Dutch)      â”‚
â”‚       citations: [                                              â”‚
â”‚         {"title": "NVAB: Werken op Hoogte", "source": "NVAB"}, â”‚
â”‚         {"title": "Arbowet Artikel 3", "source": "Arboportaal"}â”‚
â”‚       ]                                                         â”‚
â”‚       metadata: {"chunks_retrieved": 10, "chunks_cited": 2}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 11. API Streams Response to CLI                                 â”‚
â”‚     Server-Sent Events (SSE) stream:                            â”‚
â”‚       data: {"type": "text", "content": "Voor werken..."}       â”‚
â”‚       data: {"type": "text", "content": "op hoogte..."}         â”‚
â”‚       data: {"type": "citations", "data": [...]}                â”‚
â”‚       data: {"type": "end"}                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 12. CLI Displays Formatted Response                             â”‚
â”‚     ğŸ¤– Assistant:                                               â”‚
â”‚                                                                 â”‚
â”‚     Voor werken op hoogte gelden strikte veiligheidseisen.     â”‚
â”‚     Vanaf 2,5 meter hoogte is valbeveiliging verplicht...      â”‚
â”‚                                                                 â”‚
â”‚     Relevante richtlijnen:                                      â”‚
â”‚     â€¢ NVAB: Werken op Hoogte (NVAB)                            â”‚
â”‚     â€¢ Arbowet Artikel 3 (Arboportaal)                          â”‚
â”‚                                                                 â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Components

### 1. Specialist Agent (`agent/specialist_agent.py`)

**Responsibilities:**
- Receive Dutch query from API
- Decide when to search (always search first)
- Call `search_guidelines` tool with query
- Synthesize Dutch response from search results
- Format citations with guideline titles and sources
- Return structured SpecialistResponse

**Configuration:**
- Model: GPT-4 (configured via `get_llm_model()` from .env)
- System Prompt: `SPECIALIST_SYSTEM_PROMPT` (Dutch specialist behavior)
- Result Type: `SpecialistResponse` (content + citations + metadata)
- Dependencies: `SpecialistDeps` (session_id, user_id)

**Tool: search_guidelines()**
- **Purpose**: Wrapper around hybrid_search_tool
- **Input**: Dutch query string, limit (default 10)
- **Output**: List of chunks with content, scores, titles, sources
- **Behavior**: Always uses hybrid search (vector + text), no tier filtering

### 2. Search Tools (`agent/tools.py`)

**hybrid_search_tool()**
- **Input**: `HybridSearchInput(query, limit, text_weight)`
- **Process**:
  1. Generate embedding via OpenAI (`text-embedding-3-small`)
  2. Call `db_utils.hybrid_search(embedding, query_text, limit, 0.3)`
  3. Convert database rows to `ChunkResult` Pydantic models
- **Output**: List[ChunkResult]
- **Default Weights**: 70% vector similarity, 30% Dutch full-text

**vector_search_tool()** (backup, not used by default)
- Pure vector similarity search
- No keyword matching component

### 3. Database Utils (`agent/db_utils.py`)

**DatabasePool:**
- Manages asyncpg connection pool (5-20 connections)
- Lifecycle: initialized on API startup, closed on shutdown
- Timeout: 60s for SQL queries

**hybrid_search():**
- **Signature**: `async def hybrid_search(embedding: List[float], query_text: str, limit: int, text_weight: float)`
- **Process**:
  1. Convert embedding to PostgreSQL vector format: `'[0.1,0.2,...]'`
  2. Call SQL function: `SELECT * FROM hybrid_search($1::vector, $2, $3, $4)`
  3. Parse results into dictionaries
- **Returns**: List[Dict] with chunk_id, content, scores, metadata

### 4. PostgreSQL Functions (`sql/evi_schema_additions.sql`)

**hybrid_search() SQL Function:**
```sql
CREATE FUNCTION hybrid_search(
  query_embedding vector(1536),
  query_text TEXT,
  match_count INT DEFAULT 10,
  text_weight FLOAT DEFAULT 0.3
) RETURNS TABLE(...) AS $$
  WITH vector_results AS (
    SELECT *, 1 - (embedding <=> query_embedding) AS vector_sim
    FROM chunks WHERE embedding IS NOT NULL
  ),
  text_results AS (
    SELECT *, ts_rank_cd(
      to_tsvector('dutch', content),
      plainto_tsquery('dutch', query_text)
    ) AS text_sim
    FROM chunks
    WHERE to_tsvector('dutch', content) @@ plainto_tsquery('dutch', query_text)
  )
  SELECT *,
    (vector_sim * (1 - text_weight) + text_sim * text_weight) AS combined_score
  FROM vector_results FULL OUTER JOIN text_results
  ORDER BY combined_score DESC
  LIMIT match_count
$$;
```

**Key Features:**
- Dutch language support: `to_tsvector('dutch', ...)`
- Vector similarity: `<=>` operator (cosine distance)
- Combined ranking: Weighted sum of vector + text scores
- Deduplication: FULL OUTER JOIN ensures no duplicate chunks

### 5. API Server (`agent/api.py`)

**Endpoints:**
- `GET /health`: Health check (DB + Neo4j status)
- `POST /chat/stream`: Streaming chat with specialist agent
- `POST /search`: Direct search endpoint (optional, for debugging)

**Lifecycle:**
- **Startup**: Initialize DB pool, Neo4j client, run health checks
- **Shutdown**: Close DB pool, Neo4j client

**CORS Configuration:**
- Allowed origins: `http://localhost:3000, http://localhost:8058`
- Ready for future OpenWebUI integration

### 6. CLI (`cli.py`)

**Architecture:**
- Thin HTTP client (not embedding agent logic)
- Uses aiohttp for async HTTP requests
- Connects to API on `http://localhost:8058`

**Features:**
- Colored terminal output (ANSI codes)
- Streaming response display (token-by-token)
- Commands: `help`, `health`, `clear`, `exit`
- Session management (session_id persisted across queries in same session)

---

## Configuration

### Environment Variables (.env)

**Required:**
```bash
# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/evi_rag

# Neo4j (currently unused for MVP)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4jpassword

# OpenAI API
LLM_API_KEY=sk-...                           # GPT-4 for specialist agent
OPENAI_API_KEY=sk-...                        # Embeddings (can be same key)
LLM_MODEL=gpt-4                              # Or gpt-4-turbo
EMBEDDING_MODEL=text-embedding-3-small

# API Server
APP_PORT=8058                                # API listens on this port
APP_HOST=0.0.0.0                             # Bind to all interfaces
APP_ENV=development                          # development | production
LOG_LEVEL=INFO                               # DEBUG | INFO | WARNING | ERROR
```

**Optional:**
```bash
# CORS (for future OpenWebUI)
CORS_ORIGINS=http://localhost:3000,http://localhost:8058

# Search defaults (can be overridden in code)
DEFAULT_SEARCH_LIMIT=10
DEFAULT_TEXT_WEIGHT=0.3
```

### Port Configuration

**CLI Default:** `http://localhost:8058` (hardcoded in cli.py line 34)
**API Default:** Port 8000 (agent/api.py line 61) **BUT** overridden by APP_PORT in .env.example (8058)

**Startup Command:**
```bash
# Option 1: Use .env APP_PORT=8058 (recommended)
python3 -m uvicorn agent.api:app --host 0.0.0.0 --port 8058

# Option 2: Specify port explicitly
python3 -m uvicorn agent.api:app --host 0.0.0.0 --port 8058
```

**CLI Connects To:**
```bash
# CLI expects API at http://localhost:8058
# This is the default in cli.py, can be overridden with --url flag
python3 cli.py --url http://localhost:8058
```

---

## Sequence Diagram

```
User          CLI              API              Agent           Tool          DB
 â”‚             â”‚                â”‚                â”‚               â”‚              â”‚
 â”‚â”€queryâ”€â”€â”€â”€> â”‚                â”‚                â”‚               â”‚              â”‚
 â”‚             â”‚â”€POST /chatâ”€â”€â”€> â”‚                â”‚               â”‚              â”‚
 â”‚             â”‚                â”‚â”€run_stream()â”€> â”‚               â”‚              â”‚
 â”‚             â”‚                â”‚                â”‚â”€search()â”€â”€â”€â”€> â”‚              â”‚
 â”‚             â”‚                â”‚                â”‚               â”‚â”€embed()â”€â”€â”€â”€> OpenAI
 â”‚             â”‚                â”‚                â”‚               â”‚ <â”€â”€â”€â”€embeddingâ”€â”€â”€â”€â”€â”‚
 â”‚             â”‚                â”‚                â”‚               â”‚â”€search()â”€â”€> â”‚
 â”‚             â”‚                â”‚                â”‚               â”‚             â”‚â”€SQL hybrid()
 â”‚             â”‚                â”‚                â”‚               â”‚ <â”€â”€â”€â”€â”€chunksâ”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚             â”‚                â”‚                â”‚ <â”€â”€â”€â”€â”€resultsâ”€â”€â”€â”€â”€â”€â”‚              â”‚
 â”‚             â”‚                â”‚                â”‚â”€synthesizeâ”€> GPT-4 â”‚              â”‚
 â”‚             â”‚                â”‚                â”‚ <â”€Dutch responseâ”€â”€â”€â”€â”€â”€â”‚              â”‚
 â”‚             â”‚                â”‚ <â”€SpecialistResponseâ”€â”€â”€â”€â”‚               â”‚              â”‚
 â”‚             â”‚ <â”€SSE streamâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚               â”‚              â”‚
 â”‚ <â”€displayâ”€â”€â”€â”‚                â”‚                â”‚               â”‚              â”‚
```

---

## Performance Considerations

### Expected Latencies

**Breakdown (3-second target):**
1. Embedding generation: ~200-500ms (OpenAI API call)
2. Database search: ~100-300ms (vector + full-text hybrid)
3. Agent synthesis: ~1-2s (GPT-4 streaming response)
4. Network overhead: ~100-200ms (CLI â†” API â†” OpenAI)

**Total:** ~1.5-3 seconds (within target)

### Bottlenecks & Mitigation

**Potential Bottleneck:** OpenAI API latency (embedding + GPT-4)
- **Mitigation**: Use streaming for immediate feedback
- **Future**: Cache embeddings for common queries (not MVP)

**Potential Bottleneck:** Database hybrid search on 10,833 chunks
- **Mitigation**: pgvector ivfflat index already configured
- **Future**: Increase lists parameter if search slows down (currently lists=100)

**Potential Bottleneck:** Full-text search on Dutch content
- **Mitigation**: GIN index on to_tsvector('dutch', content) recommended
- **Action**: Verify index exists (not in current schema)

---

## Security Considerations

### API Authentication

**MVP:** No authentication (local development only)
**Future (FEAT-007):** Add API key or JWT for OpenWebUI

### Input Validation

**CLI â†’ API:** FastAPI Pydantic models validate input
**Agent â†’ Tools:** Pydantic Input models validate parameters
**SQL Injection:** Prevented by parameterized queries ($1, $2, etc.)

### Data Privacy

**Session IDs:** Generated UUIDs, no PII stored
**Guideline Content:** Public workplace safety guidelines (non-sensitive)
**Logs:** Avoid logging full guideline content (only metadata)

---

## Error Handling

### Common Errors & Responses

**Database Connection Failure:**
- **Trigger**: PostgreSQL container down
- **Detection**: API `/health` endpoint returns 500
- **Response**: CLI shows "âœ— API is unhealthy"
- **Recovery**: Restart Docker containers

**Embedding API Failure:**
- **Trigger**: OpenAI API key invalid or quota exceeded
- **Detection**: `generate_embedding()` raises exception
- **Response**: Tool returns empty results, agent responds "Kan momenteel niet zoeken"
- **Recovery**: Fix .env LLM_API_KEY, check OpenAI quota

**No Search Results:**
- **Trigger**: Query doesn't match any chunks (unlikely with 10,833 chunks)
- **Detection**: hybrid_search returns empty list
- **Response**: Agent responds "Geen relevante richtlijnen gevonden in de kennisbank"
- **Recovery**: User rephrases query

**Agent Timeout:**
- **Trigger**: GPT-4 takes >60s to respond (very rare)
- **Detection**: Pydantic AI timeout
- **Response**: API returns 504 Gateway Timeout
- **Recovery**: Retry query, check OpenAI status

---

## Testing Strategy

### Unit Tests

**Agent Tests:**
- `test_specialist_search_tool()`: Verify search tool calls hybrid_search
- `test_dutch_output()`: Validate responses are in Dutch
- `test_citation_format()`: Check citations include title + source

**Tool Tests:**
- `test_hybrid_search_tool()`: Mock embedding, verify SQL call
- `test_vector_search_tool()`: Test fallback search method

**Database Tests:**
- `test_hybrid_search_function()`: Direct SQL function call
- `test_dutch_stemming()`: Verify "werken" matches "werk"

### Integration Tests

**End-to-End Flow:**
1. Start API in test mode
2. Send test query via HTTP POST
3. Validate response structure and Dutch content
4. Verify citations include â‰¥2 guidelines
5. Check response time <3 seconds

**Test Queries:** (See PRD testing section)
- "Wat zijn de vereisten voor werken op hoogte?"
- "Hoe voorkom ik rugklachten bij werknemers?"
- ...10 total queries

### Manual Testing

**Checklist:**
- [ ] API starts without errors
- [ ] CLI connects to API successfully
- [ ] Dutch queries accepted without encoding issues
- [ ] Responses are grammatically correct Dutch
- [ ] Citations include NVAB, STECR, UWV, or Arboportaal sources
- [ ] Response time <3 seconds for 8/10 queries
- [ ] No crashes during 10-query session

---

## Deployment

### Local Development

```bash
# 1. Start infrastructure
docker-compose up -d

# 2. Activate venv
source venv_linux/bin/activate

# 3. Start API server
python3 -m uvicorn agent.api:app --host 0.0.0.0 --port 8058 --reload

# 4. In separate terminal, run CLI
python3 cli.py
```

### Production (Future)

**Not in scope for MVP**
- Dockerize API server
- Use gunicorn + uvicorn workers
- Add authentication middleware
- Configure CORS for production domains
- Use managed PostgreSQL (not Docker)

---

## Future Enhancements

**Post-MVP features (documented in separate PRDs):**

**FEAT-007: OpenWebUI Integration**
- OpenAI-compatible `/v1/chat/completions` endpoint
- Web UI for non-technical users
- Multi-user session management

**FEAT-008: Advanced Memory**
- Session-based conversation context
- Entity tracking across queries
- Graph-based memory (Neo4j)

**FEAT-009: Tier-Aware Search**
- Enable tier column usage (currently NULL)
- Tier traversal strategy (Tier 1 â†’ 2 â†’ 3)
- Adaptive tier selection based on query complexity

**FEAT-004: Product Catalog**
- Scrape EVI 360 website products
- AI categorization and compliance tagging
- Product recommendation integration with specialist agent

**FEAT-005: Multi-Agent System**
- Separate Research Agent (handles search)
- Specialist Agent calls Research Agent as tool
- Agent-calling-agent pattern for complex workflows

**FEAT-006: Knowledge Graph**
- Populate Neo4j with Graphiti
- Guideline relationship mapping
- Enable graph_search tool in specialist agent

---

## References

**Code:**
- Specialist Agent: `agent/specialist_agent.py` (to be created)
- Search Tools: `agent/tools.py` (existing)
- Database Utils: `agent/db_utils.py` (existing)
- API Server: `agent/api.py` (existing, needs modification)
- CLI: `cli.py` (existing, no changes)

**Documentation:**
- PRD: `docs/features/FEAT-003_query-retrieval/prd.md`
- Implementation Guide: `docs/features/FEAT-003_query-retrieval/implementation-guide.md` (to be created)
- System Architecture: `docs/system/architecture.md`
- Database Schema: `sql/schema.sql`, `sql/evi_schema_additions.sql`

**External:**
- Pydantic AI Docs: https://ai.pydantic.dev
- pgvector Docs: https://github.com/pgvector/pgvector
- PostgreSQL Dutch Text Search: https://www.postgresql.org/docs/current/textsearch-dictionaries.html

---

**Decision Status:** Proposed
**Next Steps:**
1. Review this architecture with team
2. Proceed to implementation-guide.md for code changes
3. Create specialist_agent.py and specialist_prompt.py
4. Modify agent/api.py to register specialist agent
5. Test end-to-end flow with 10 Dutch queries
