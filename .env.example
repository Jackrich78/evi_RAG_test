# =============================================================================
# EVI 360 RAG System - Environment Configuration Template
# =============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control!

# =============================================================================
# Database Configuration
# =============================================================================

# Supabase/PostgreSQL connection (with pgvector extension)
# Format: postgresql://user:password@host:port/database
DATABASE_URL=postgresql://postgres:password@localhost:5432/evi_rag

# Neo4j graph database connection
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password123

# =============================================================================
# Notion API Configuration
# =============================================================================

# Notion API token from https://www.notion.so/my-integrations
NOTION_API_TOKEN=secret_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Notion database ID for guidelines (32 hex characters from database URL)
NOTION_GUIDELINES_DATABASE_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# LLM Provider: openai, ollama, openrouter, gemini
LLM_PROVIDER=openai

# OpenAI API Configuration
LLM_BASE_URL=https://api.openai.com/v1
LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Model for chat/specialist agent (use a capable model)
LLM_CHOICE=gpt-4-turbo-preview

# Model for ingestion/categorization (can use faster/cheaper model)
INGESTION_LLM_CHOICE=gpt-3.5-turbo

# =============================================================================
# Embedding Configuration
# =============================================================================

# Embedding provider: openai, ollama
EMBEDDING_PROVIDER=openai

# OpenAI embedding model (1536 dimensions)
EMBEDDING_MODEL=text-embedding-3-small

# Embedding API key (if different from LLM_API_KEY)
EMBEDDING_API_KEY=${LLM_API_KEY}

# =============================================================================
# Language Configuration
# =============================================================================

# Output language for agent responses (nl=Dutch, en=English)
OUTPUT_LANGUAGE=nl

# =============================================================================
# Application Configuration
# =============================================================================

# Application environment
APP_ENV=development

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# API server port
APP_PORT=8058

# =============================================================================
# Ingestion Configuration
# =============================================================================

# Chunk size for semantic chunking (tokens)
CHUNK_SIZE=1000

# Chunk overlap (tokens)
CHUNK_OVERLAP=200

# Maximum chunk size (tokens)
MAX_CHUNK_SIZE=2000

# Enable semantic chunking (true/false)
USE_SEMANTIC_CHUNKING=true

# Skip knowledge graph building for faster ingestion (true/false)
SKIP_GRAPH_BUILDING=false

# =============================================================================
# EVI 360 Specific Configuration
# =============================================================================

# EVI 360 website base URL for product scraping
EVI360_BASE_URL=https://www.evi360.nl

# Product scraping rate limit (requests per second)
SCRAPING_RATE_LIMIT=1.0

# Product categorization batch size
CATEGORIZATION_BATCH_SIZE=10

# =============================================================================
# Session and Security Configuration
# =============================================================================

# Session expiration time (hours)
SESSION_EXPIRATION_HOURS=24

# CORS allowed origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8058

# Enable debug mode (true/false) - DO NOT USE IN PRODUCTION
DEBUG=false

# =============================================================================
# Optional: Alternative LLM Providers
# =============================================================================

# Ollama (local models)
# LLM_PROVIDER=ollama
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_CHOICE=llama3:8b
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_MODEL=nomic-embed-text

# OpenRouter (multiple models)
# LLM_PROVIDER=openrouter
# LLM_BASE_URL=https://openrouter.ai/api/v1
# LLM_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# LLM_CHOICE=anthropic/claude-3-opus

# Google Gemini
# LLM_PROVIDER=gemini
# LLM_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# LLM_CHOICE=gemini-pro
